{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-fancy",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-marathon",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* [Оптимизация функций градиентым спуском](#Оптимизация-функций-градиентым-спуском)\n",
    "    * [Градиентный спуск для одномерной функции](#Градиентный-спуск-для-одномерной-функции)\n",
    "    * [Градиентный спуск для функции двух переменных](#Градиентный-спуск-для-функции-двух-переменных)\n",
    "    * [Autograd](#Autograd)\n",
    "\n",
    "Для начала реализуем функции, необходимые нам для визуализации. Визуализации функции одной переменной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-ministry",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_1d_fuction(xs: list, ys: list, title: str, figsize=(15, 5)):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    xs – значения функции по x\n",
    "    ys – значения функции по y\n",
    "    \n",
    "    title – заголовок картинки\n",
    "    msg – информация для отображения на картинке\n",
    "    \n",
    "    figsize – размер картинки\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(xs, ys, 'b')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('$f(x)$')\n",
    "    plt.xlabel('$x$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-surrey",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Функция для отрисовки графика и значение функции в точке x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-preserve",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_line_with_x(xs: list, ys: list, x: float, fx: float, title: str, msg='', figsize=(15, 5)):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    xs – значения функции по x\n",
    "    ys – значения функции по y\n",
    "    \n",
    "    x – текущее положение точки по x\n",
    "    fx – текущее положение точки по y\n",
    "    \n",
    "    title – заголовок картинки\n",
    "    msg – информация для отображения на картинке\n",
    "    \n",
    "    figsize – размер картинки\n",
    "    '''\n",
    "    \n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(xs, ys, 'b')\n",
    "    plt.scatter([x], [fx], c='r', marker='x', s=120)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.ylabel('$f(x)$')\n",
    "    plt.xlabel('$x$')\n",
    "    plt.text(s=msg, x=-2, y=103)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-ordinary",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p>Начнем с поиска минимума полинома шестой&nbsp;степени <span class=\"math-tex\">\\(f(x) = x^6 + 3x^5 - 15x^3-24x^2+15x-10\\)</span>. Реализуем функцию для вычисления значений&nbsp;<span class=\"math-tex\">\\(f\\)</span>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-cartridge",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def f_1d(x):\n",
    "    return (x ** 6) + 3 * (x ** 5) - 15 * (x ** 3) - 24 * (x ** 2) + 15 * x - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-sleep",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Нарисуем график функции на отрезке от -3 до 2.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-opportunity",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "title_f_1d = '$f(x) = x^{6} + 3x^{5} - 15x^{3} - 24x^{2} + 15x - 10$'\n",
    "\n",
    "xs = np.linspace(-3, 2.5)\n",
    "ys = f_1d(xs)\n",
    "\n",
    "plot_1d_fuction(xs, ys, title=title_f_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-regulation",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Видим, что у функции два минимума.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-equipment",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p>Алгоритм градиентного спуска в самом общем виде выглядит так:</p>\n",
    "\n",
    "<p><code>until converge:<br />\n",
    "&nbsp; &nbsp; x = x - alpha * grad(f(x))</code></p>\n",
    "\n",
    "<p>где <code>alpha</code> &mdash; это скорость обучения (то, как сильно мы меняем своё положение на каждом шаге).</p>\n",
    "\n",
    "<p>Для выхода из цикла будем использовать одно&nbsp;из двух условий:</p>\n",
    "\n",
    "<ol>\n",
    "\t<li>Если количество итераций превышает максимально допустимое. Это условие необходимо, чтобы не ждать слишком долго &mdash; если что-то пошло не так и&nbsp;поиск оптимальной точки занимает слишком много итераций при текущих параметрах;</li>\n",
    "\t<li>Если градиент становится слишком маленьким по абсолютным значениям. В этом случае мы&nbsp;будем находиться в одном из двух минимумов нашей функции.</li>\n",
    "</ol>\n",
    "\n",
    "<p>Вычислим градиент функции:</p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(f'_x = 6x^5 + 15x^4 - 45x^2 - 48x + 15\\)</span></p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p>Реализуем функцию для его вычисления в нужной нам точке:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-complaint",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def grad(x):\n",
    "    return 6 * (x ** 5) + 15 * (x ** 4) - 45 * (x ** 2) - 48 * x + 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-register",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p>Всё готово для поиска минимума функции <span class=\"math-tex\">\\(f\\)</span> методом градиентного спуска.<br />\n",
    "&nbsp;</p>\n",
    "\n",
    "<p>Начнем с точки <span class=\"math-tex\">\\(x_0=0.2\\)</span>, величину шага&nbsp;<span class=\"math-tex\">\\(\\alpha\\)</span>&nbsp;примем равной <span class=\"math-tex\">\\(0.03\\)</span>&nbsp;и будем останавливать итерации, если абсолютное значение градиента не превышает&nbsp;<span class=\"math-tex\">\\(10^{-4}\\)</span>&nbsp;(параметр <code>tol</code>).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-composition",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.03\n",
    "tol = 1e-4\n",
    "\n",
    "x = 0.2\n",
    "\n",
    "max_iteration = 200\n",
    "iteration = 0\n",
    "\n",
    "dfdx = np.inf\n",
    "\n",
    " \n",
    "while iteration < max_iteration and abs(dfdx) > tol:\n",
    "    \n",
    "    iteration += 1\n",
    "    plot_line_with_x(xs, ys, x, f_1d(x), msg=f'iteration number: {iteration}', title=title_f_1d)\n",
    "    \n",
    "    dfdx = grad(x)\n",
    "    x = x - alpha * dfdx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-moldova",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p>Видим, что оптимизации из этой стартовой точки c alpha=0.03 приводим к колебаниям в районе локального минимума.</p>\n",
    "<p>Попробуем начать их с точки&nbsp;<span class=\"math-tex\">\\(x_0=-3.05\\)</span>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-cincinnati",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alpha = -3.05\n",
    "tol = 1e-4\n",
    "\n",
    "x = 0.2\n",
    "\n",
    "max_iteration = 200\n",
    "iteration = 0\n",
    "\n",
    "dfdx = np.inf\n",
    "\n",
    " \n",
    "while iteration < max_iteration and abs(dfdx) > tol:\n",
    "    \n",
    "    iteration += 1\n",
    "    plot_line_with_x(xs, ys, x, f_1d(x), msg=f'iteration number: {iteration}', title=title_f_1d)\n",
    "    \n",
    "    dfdx = grad(x)\n",
    "    x = x - alpha * dfdx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-motorcycle",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p>Такая стартовая точка приводит к тому, что градиент становится всё больше и больше с каждой итерацией алгоритма&nbsp;&mdash; и в результате <span class=\"math-tex\">\\(x\\)</span>&nbsp;уходит&nbsp;так далеко от минимумов функции, что тип <code>float</code> переполняется. Справиться с этой проблемой можно с помощью&nbsp;клиппинга градиента: будем&nbsp;ограничивать максимальное абсолютное значение у переменной<code>dfdx</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-theory",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.003\n",
    "tol = 1e-4\n",
    "\n",
    "x = 2.5\n",
    "\n",
    "max_iteration = 200\n",
    "iteration = 0\n",
    "\n",
    "dfdx = np.inf\n",
    "\n",
    "\n",
    "while iteration < max_iteration and abs(dfdx) > tol:\n",
    "    \n",
    "    iteration += 1\n",
    "    plot_line_with_x(xs, ys, x, f_1d(x), msg=f'iteration number: {iteration}', title=title_f_1d)\n",
    "    \n",
    "    dfdx = np.clip(grad(x), -10, 10)\n",
    "    x = x - alpha * dfdx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-album",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Градиентный спуск для функции двух переменных\n",
    "Для экспериментов с функциями от двух переменных сначала реализуем функции для визуализации.\n",
    "\n",
    "Визуализация 2d функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-buyer",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_2d_function(W, B, J, title, figsize=(12, 8)):\n",
    "    \n",
    "    '''\n",
    "    W – матрица параметров по оси x\n",
    "    B – матрица параметров по оси y\n",
    "    J – функция которую мы будем оптимизировать\n",
    "    \n",
    "    title – заголовок картинки\n",
    "    '''\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.contourf(W, B, J, levels=25)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('$b$')\n",
    "    plt.xlabel('$W$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-malta",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p>Для примера мы будем находить минимум функции&nbsp;</p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(J(w, b) = (w - 25)^2 + (2b - 22)^2 + (w - 25)(2b - 22)\\)</span></p>\n",
    "\n",
    "<p>на отрезках&nbsp;<span class=\"math-tex\">\\([-5, 36]\\)</span>&nbsp;и&nbsp;<span class=\"math-tex\">\\([-5, 50]\\)</span>&nbsp; для&nbsp;<span class=\"math-tex\">\\(w\\)</span>&nbsp;и <span class=\"math-tex\">\\(b\\)</span>&nbsp;соответственно.</p>\n",
    "\n",
    "<p>Для того, чтобы использовать метод градиентного спуска, посчитаем градиент функции <span class=\"math-tex\">\\(J\\)</span> по каждому из параметров:</p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(J_{w}' = 2(w - 25) + (2b - 22)\\)</span></p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(J'_{b} = 4(2b - 22) + 2(w - 25)\\)</span></p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p>Реализуем функцию для получения значений&nbsp;<span class=\"math-tex\">\\(J\\)</span>, <span class=\"math-tex\">\\(\\frac{\\partial J}{\\partial w}\\)</span>&nbsp;и <span class=\"math-tex\">\\(\\frac{\\partial J}{\\partial b}\\)</span>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-stationery",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "W_RANGE = (-5, 36)\n",
    "B_RANGE = (-5, 50)\n",
    "\n",
    "\n",
    "def f_2d(w, b):\n",
    "    \n",
    "    '''Функцию для получения значений J.'''\n",
    "    \n",
    "    return (w - 25) ** 2 + (2 * b - 22) ** 2 + (w - 25) * (2 * b - 22)\n",
    "\n",
    "\n",
    "def grad_w(w, b):\n",
    "    \n",
    "    '''Функцию для получения значений производной функции J по параметру w.'''\n",
    "    \n",
    "    return 2 * (w - 25) + 2 * b - 22\n",
    "\n",
    "\n",
    "def grad_b(w, b):\n",
    "    \n",
    "    '''Функцию для получения значений производной функции J по параметру b.'''\n",
    "    \n",
    "    return 4 * (2 * b - 22) + 2 * (w - 25)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-consultation",
   "metadata": {},
   "source": [
    "<p>&nbsp;Функция, которая генерирует матрицы значений для параметров <span class=\"math-tex\">\\(w\\)</span>, <span class=\"math-tex\">\\(b\\)</span> и функции <span class=\"math-tex\">\\(J\\)</span>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_parameter_space(wrange=W_RANGE, brange=B_RANGE, num=100, function=f_2d):\n",
    "    \n",
    "    '''Функция, которая генерирует матрицы значений для параметров'''\n",
    "    \n",
    "    w_grid = np.linspace(W_RANGE[0], W_RANGE[1], num=num)\n",
    "    b_grid = np.linspace(B_RANGE[0], B_RANGE[1], num=num)\n",
    "\n",
    "    W, B = np.meshgrid(w_grid, b_grid)\n",
    "    J = function(W, B)\n",
    "    \n",
    "    return W, B, J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-medicare",
   "metadata": {},
   "source": [
    "<p>Визуализация градиентного спуска: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_gradient_descent(W, B, J, ws: list, bs: list, title: str, iteration_number: int,\n",
    "                             figsize=(8, 12), levels=25):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    W – матрица параметров по оси x\n",
    "    B – матрица параметров по оси y\n",
    "    J – функция, которую мы будем оптимизировать\n",
    "    \n",
    "    ws – список с историей координат точки по оси x\n",
    "    bs – список с историей координат точки по оси y\n",
    "    \n",
    "    title – заголовок картинки\n",
    "    \n",
    "    iteration_number – номер итерации\n",
    "    figsize – размер картинки\n",
    "    \n",
    "    levels – количество линий уровня для отображения\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    clear_output(True)\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    fig.set_figheight(figsize[0])\n",
    "    fig.set_figwidth(figsize[1])\n",
    "\n",
    "    cs = ax.contourf(W, B, J, levels=levels)\n",
    "    ax.plot(ws, bs, 'r')\n",
    "\n",
    "    iteration_msg = f'iteration: {iteration_number}' \n",
    "    parameters_msg = f'b: {round(bs[-1], 1)}, w: {round(ws[-1], 1)}'\n",
    "    \n",
    "    x_text_loc = W_RANGE[0] + (W_RANGE[1] - W_RANGE[0]) / 10\n",
    "    y_text_loc = B_RANGE[0] + (B_RANGE[1] - B_RANGE[0]) / 2\n",
    "    \n",
    "    plt.text(\n",
    "        s=iteration_msg + '\\n' + parameters_msg,\n",
    "        c='w', x=x_text_loc, y=y_text_loc\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.ylabel('$b$')\n",
    "    plt.xlabel('$W$')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-title",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p>Реализуем оптимизацию с помощью цикла <code>while</code> с условием выхода, завязанным на количество итераций и норму вектора градиента:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-fields",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "W, B, J = get_function_parameter_space()\n",
    "title_f_2d = '(W - 25) ** 2 + (2 * B - 22) ** 2 + (W - 25) * (2 * B - 22)'\n",
    "\n",
    "w, b = 0., 0.\n",
    "\n",
    "ws = [w]\n",
    "bs = [b]\n",
    "\n",
    "iteration_number = 0\n",
    "alpha = 0.22\n",
    "tol = 1e-4\n",
    "\n",
    "dJdw, dJdb = np.inf, np.inf\n",
    "\n",
    "while iteration_number < 200 and np.linalg.norm([dJdw, dJdb]) > tol:\n",
    "    \n",
    "    dJdw = grad_w(w, b)\n",
    "    dJdb = grad_b(w, b)\n",
    "    \n",
    "    w = w - alpha * dJdw\n",
    "    b = b - alpha * dJdb\n",
    "    \n",
    "    iteration_number += 1\n",
    "    \n",
    "    plot_2d_gradient_descent(W, B, J, ws, bs, title=title_f_2d, iteration_number=iteration_number)\n",
    "    \n",
    "    ws.append(w)\n",
    "    bs.append(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-genre",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p>Для того, чтобы уменьшить осцилляции, можно добавить импульс. Для этого на каждом шаге алгоритма&nbsp;будем учитывать не только направление градиента в текущей точке, но и&nbsp;градиент на предыдущем шаге. Алгоритм обновления весов для параметра <span class=\"math-tex\">\\(w\\)</span>&nbsp;будет выглядеть так:</p>\n",
    "\n",
    "<p style=\"text-align:center\"><br />\n",
    "<span class=\"math-tex\">\\(v_{w}^{t} = \\beta v_{w}^{t-1} + (1 - \\beta)\\frac{\\partial J}{\\partial w}\\)</span><br />\n",
    "<span class=\"math-tex\">\\(w^{t} = w^{t-1} - \\alpha v_{w}^{t}\\)</span></p>\n",
    "\n",
    "<p>С добавлением импульса у нас появился дополнительный параметр <code>beta</code>, который будет регулировать, в каком соотношении мы будем учитывать градиент на предыдущем&nbsp;шаге и в данный момент.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-margin",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w, b = 0, 0\n",
    "\n",
    "ws = [w]\n",
    "bs = [b]\n",
    "\n",
    "iteration_number = 0\n",
    "alpha = 0.22\n",
    "tol = 1e-4\n",
    "\n",
    "dJdw, dJdb = np.inf, np.inf\n",
    "\n",
    "v_w, v_b = 0, 0\n",
    "beta = 0.25\n",
    "\n",
    "while iteration_number < 200 and np.linalg.norm([dJdw, dJdb]) > tol:\n",
    "    \n",
    "    dJdw = 2 * (w - 25) + (2 * b - 22)\n",
    "    dJdb = 4 * (2 * b - 22) + 2 * (w - 25)\n",
    "    \n",
    "    v_w = v_w * beta + dJdw * (1 - beta)\n",
    "    w = w - alpha * v_w\n",
    "    \n",
    "    v_b = v_b * beta + dJdb * (1 - beta)\n",
    "    b = b - alpha * v_b\n",
    "\n",
    "    iteration_number += 1\n",
    "    time.sleep(0.1 / iteration_number)\n",
    "    \n",
    "    plot_2d_gradient_descent(W, B, J, ws, bs, title=title_f_2d, iteration_number=iteration_number)\n",
    "    \n",
    "    ws.append(w)\n",
    "    bs.append(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-million",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "С добавлением импульса скорость поиска минимума заметно возросла — удалось найти минимум за 28 итераций алгоритма вместо 128 итераций для реализации без импульса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-marina",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p>Для тестирования алгоритмов оптимизации&nbsp;есть <a href=\"https://en.wikipedia.org/wiki/Test_functions_for_optimization\" rel=\"noopener noreferrer nofollow\">специальные функции</a>.</p>\n",
    "\n",
    "<p>Чтобы прочувствовать нюансы, которые мы обсуждали на семинаре, попробуйте найти минимумы одной из следующих функций:</p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(f(x,y)=2x^{2}-1.05x^{4}+{\\frac {x^{6}}{6}}+xy+y^{2}\\)</span>&nbsp;&ndash; Three-hump camel function</p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(f(x,y)=\\sin \\left(x+y\\right)+\\left(x-y\\right)^{2}-1.5x+2.5y+1\\)</span>&nbsp;&ndash; McCormick function</p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(f(x,y)=0.26\\left(x^{2}+y^{2}\\right)-0.48xy\\)</span>&nbsp;&ndash; Matyas function</p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(f(x,y)=\\left(x+2y-7\\right)^{2}+\\left(2x+y-5\\right)^{2}\\)</span>&nbsp;&ndash; Booth function</p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(f(x,y)=\\left(1.5-x+xy\\right)^{2}+\\left(2.25-x+xy^{2}\\right)^{2} {\\displaystyle +\\left(2.625-x+xy^{3}\\right)^{2}}+\\left(2.625-x+xy^{3}\\right)^{2}\\)</span>&nbsp;&ndash; Beale function</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-minimum",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Autograd\n",
    "В библиотеках для работы с deeplearning, таких как Pytorch и Tensorflow, есть функционал для автоматического вычисления градиента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-conspiracy",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def f_1d(x):\n",
    "    return (x ** 6) + 3 * (x ** 5) - 15 * (x ** 3) - 24 * (x ** 2) + 15 * x - 10\n",
    "\n",
    "def grad(x):\n",
    "    return 6 * (x ** 5) + 15 * (x ** 4) - 45 * (x ** 2) - 48 * x + 15\n",
    "\n",
    "\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "y = f_1d(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-baking",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ".backward() — функция для расчёта градиента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-conviction",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-district",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "После выполнения функции градиент хранится в переменной $x$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-mouth",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-valuable",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проверим, что Pytorch правильно выполнил вычисление градиента с помощью нашей функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-participation",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grad(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
